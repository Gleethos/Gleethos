



<div class="col-sm-12 col-md-12 col-lg-12">
    <div class="ContentBox">
        <h2>Neureka?</h2>
        <p>
                <a href="https://gleethos.github.io/neureka/index.html">Neureka</a> is a lightweight open source
                machine learning / deep learning tensor library that I wrote in Java. <br><br>
                I chose this language because it is platform independent and also
                because it is a central language to the entire JVM ecosystem. <br>
                <img src="src/img/icons/oil-offshore-rig.png">
                Neureka is 100% platform independent and compatible with any JVM language,
                such as Groovy, Scala, Clojure or Kotlin.
                <br>
                I started working on Neureka because I
                couldn't find a suitable alternative to the novel ideas
                expressed in libraries like Torch or PyTorch in the JVM ecosystem. <br>
                <br>
        </p>
    </div>
</div>

<div class="col-sm-12 col-md-6 col-lg-5">
    <div class="ContentBox">
        <p>
                The library is completely open-source, free to use,
                and of course MIT-Licenced. <img src="src/img/icons/open-source.png">
                In a sense it is more of a personal research project,
                at least that is how I viewed it when I started working on it. <br>
                I initially started Neureka to implement ML/DL ideas I encountered <br>
                from scratch simply because I wanted to understand them. <br>
                However now it has become a fairly powerful tool!
        </p>
    </div>
</div>
<div class="col-sm-12 col-md-6 col-lg-4">
    <div class="ContentBox">
        <p>
            Neureka features an OpenCL accelerated backend in order to
            not tie it to any hardware vendor... <br><img src="src/img/icons/video-card.png">
            I learned a great deal about how the magic of Deep-Learning
            really works under the hood when writing OpenCL kernel code.<br>

        </p>
    </div>
</div>
<div class="col-sm-12 col-md-12 col-lg-3">
    <div class="ContentBox">
        <p>
                A lot of effort went in making the backends of Neureka
                as extensible as possible. <br><img style="max-width: 4em;"src="src/img/icons/puzzle.png">
                Implementing new backends for faster execution is therefore easily possible.
        </p>
    </div>
</div>
<div class="col-sm-12 col-md-12 col-lg-12">
    <div class="ContentBox">
        <p>
            Take a look at some Groovy code making use of the library:
        </p>
    </div>
</div>
<div class="col-sm-12 col-md-12 col-lg-12">
    <div class="TabWrapper">
        <div class="TabHead">
            <button onclick="switchTab(event, '.tensorTab')" class="selected">Tensors</button>
            <button onclick="switchTab(event, '.simpleNNTab')">Simple Neural Network</button>
        </div>
        <div class="TabBody">
            <div class="tensorTab">
                <pre><code class="hljs java">
    Tsr t = Tsr.of([2, 4],[
                        1, 2, 3, 4,
                        9, 8, 6, 5
                   ])
                </code></pre>
            </div>
            <div class="simpleNNTab" style="display:none">
                <pre><code class="hljs java">

    void runOn(Device device)
    {
        Tsr X = Tsr.of( // input data: 5 vectors in binary form
                        [5, 3, 1],
                        [
                            0, 0, 1,
                            1, 1, 0,
                            1, 0, 1,
                            0, 1, 1,
                            1, 1, 1
                        ]
                    )

        X.set(device) // We move the tensor over to the GPU memory...

        Tsr y = Tsr.of( [5, 1, 1], [0,1,1,1,0] ).set(device) // output values (labels)

        Tsr input = X
        Tsr weights1 = Tsr.of(
                            [1, input.shape()[1], 4],
                            [
                                4.17022005e-01, 7.20324493e-01, 1.14374817e-04, 3.02332573e-01,
                                1.46755891e-01, 9.23385948e-02, 1.86260211e-01, 3.45560727e-01,
                                3.96767474e-01, 5.38816734e-01, 4.19194514e-01, 6.85219500e-01
                            ]
                        ).set(device)

        Tsr weights2 = Tsr.of([1, 1, 4], [0.20445225, 0.87811744, 0.02738759, 0.67046751]).set(device)
        Tsr output = Tsr.of(y.shape(), [0.0, 0.0, 0.0, 0.0, 0.0]).set(device)
        Tsr layer1 = Tsr.of()

        // iterate 500 times
        for( i in 0..500) {
            feedforward(weights1, weights2, input, output, layer1)
            backprop(weights1, weights2, input, output, layer1, y)
        }
    }

    Tsr sigmoid(Tsr x) { return Tsr.of("sig(I[0])", x) }

    Tsr sigmoid_derivative(Tsr x) { return x * (-x + 1) }

    void feedforward(Tsr weights1, Tsr weights2, Tsr input, Tsr output, Tsr layer1) {
        Tsr in0 = Tsr.of("i0 x i1", input, weights1)  // Convolution / Matrix Multiplication
        layer1[] = sigmoid(in0)
        Tsr in1 = Tsr.of("i0 x i1", layer1, weights2)
        output[] = sigmoid(in1)
    }

    void backprop(Tsr weights1, Tsr weights2, Tsr input, Tsr output, Tsr layer1, Tsr y) {
    // application of the chain rule to find derivative of the loss function with respect to weights2 and weights1
        Tsr delta = (y - output) * 2
        Tsr derivative = delta * 2 * sigmoid_derivative(output)
        Tsr d_weights2 = Tsr.of( "i0 x i1", layer1, (derivative) )
        Tsr d_weights1 = Tsr.of(
                                "i0 x i1",
                                input,
                                (Tsr.of("i0xi1", derivative, weights2) * sigmoid_derivative(layer1)),
                        )
        // update the weights with the derivative (slope) of the loss function
        weights1[] = weights1 + d_weights1
        weights2[] = weights2 + d_weights2
    }

                </code></pre>
            </div>
        </div>
    </div>
</div>

